{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que haré es abrir convertir los doas archivos csv en data frame y unirlos en uno solo por que si bien luego lo enviaré a mysql, que en teoria es relacional la información es totalmente complementaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este código se usa para poder visualizar todas las filas de un data frame muy largo\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leo y visualizo df_hechos con la información original\n",
    "\n",
    "df_hechos = pd.read_csv('hechos.csv', sep=';')\n",
    "df_hechos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hechos.info()\n",
    "# Se puede verificar que este df tiene 20 filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leo y visualizo df_victimas  con la información original\n",
    "\n",
    "df_victimas = pd.read_csv('victimas.csv', sep=';')\n",
    "df_victimas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_victimas.info()\n",
    "# Se puede verificar que son 9 filas, es decir que sumadas serán 29 filas, se utilizará este numero para la configuración de tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio el nombre de la columna ID_hechos para poder hacel el join con la informacion víctimas\n",
    "\n",
    "df_victimas.rename(columns={'ID_hecho': 'ID'}, inplace=True)\n",
    "df_victimas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unifico y visualizo los dos df anteriores para hacer las transformaciones necesarias y poder mejorar la información\n",
    " \n",
    "df_siniestros = pd.merge(df_hechos, df_victimas, on='ID', how='inner')\n",
    "df_siniestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_siniestros.info()\n",
    "# Se pueden ver 29 filas, lo que asegura que en este dataframe quedó la totalidad de la información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien la idea es dejar toda la información en una base de datos, se puede mejorar la presentación pues hay mucha información repetida que se puede dejar en una sola columna con el mismo formato tal como el año, así que iré columna por columna para entender y modificar su forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifico el tipo de columnas (ID) para poder comparar registro y encontrar posteriormente duplicados\n",
    "\n",
    "tipos_columna_ID = df_siniestros.dtypes\n",
    "print(tipos_columna_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que el tipo de la columna ID es objeto primero convertiré en strn para poder extraer los ultimos 4 digitor referentes al indicador\n",
    "\n",
    "df_siniestros['ID'] = df_siniestros['ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora si extraeré los ultimos 4 dígitos en una nueva columna \"IDENTIFICADOR\"\n",
    "\n",
    "df_siniestros['IDENTIFICADOR'] = df_siniestros['ID'].astype(str).str[-4:]\n",
    "df_siniestros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dejo la ultima columna de primeras pues por ser el identificador es el mas importante para la organización de los datos\n",
    "\n",
    "# Cambiar la ubicación de la columna 'C' a la primera posición\n",
    "\n",
    "df_siniestros = df_siniestros[[\"IDENTIFICADOR\"] + [col for col in df_siniestros.columns if col != \"IDENTIFICADOR\"]]\n",
    "df_siniestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de dataframe\n",
    "df_siniestros.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguietes analisis columna por columna para el EDA serán:\n",
    "\n",
    "\n",
    "* Fecha siniestro: esta la columna FECHA_xx tiene formato correcto y completo, y la información es necesaria\n",
    "* La Columna AAAA_xx que se refiere al año se podrá  extraer en PowerBI después, así que prefiero borrarle, así mismo pasará con  MM_x (8mes) y dd_x (día), por lo que las borraré\n",
    "* La columna Hora tiene  con un formato correcto y es información relevante, posterior cambiaré todos los títulos\n",
    "* La columna HH se refiere a la franja horaria, lo cual no tiene mucho sentido con tantos números, será inteligente\n",
    "dejar la columna como franja horaria  pero dejar solo 3 franjas horarias: mañana, tade y noche o depronto solo AM y PM\n",
    "* LUGAR_DEL_HECHO: dirección del hecho, strn, lo dejaré pero lo más posible es que no se use pues será mas apropiado las coordenadas para poder ubicar en PBI. La idea de tener la dirección del hecho es poder ubicarlo en el mapa, sinembargo la forma mas facil de ubicacion en PBI son las \n",
    "coordenadas, se podrá revisar por barrios pero la dirección no sirve de mucho, así que se podrá borrar\n",
    "* TIPO_DE_CALLE: Tenendo las coordenadas, esta información es irrelevante por lo anterior la borraré\n",
    "* ACUSADO. Es una información importante pues rendirá cuenta de que tipo de acusado suele tener mas culpabilidad, \n",
    "* VICTIMA: En los dos dataframe hay columnas víctimas y en las dos se refieren al vehículo que opcupaba la víctima; Así que borro una de las columnas víctima y dejo una única columna llamada VICTIMA\n",
    "* FECHA_x,AAAA_x,MM_x,DD_x\tDecido borrar esta columna después de verificar que es exactamente la misma información que la columna FECHA_x desagregada, esa desagregación se puede hacer directamente PBI\n",
    "* La columna XY(CABA), se refiere a la geocodificacion plana, Se tienen las coordenadas por lo que esta información es irrelevante por lo dejaré y si es necesaria la utilizaré en la visualización\n",
    "POS\n",
    "* pos x\tpos y: Esta es una información muy importante y se refiere a la longitud y latitud en el formato correcto en el que PBI lo ubica, así que cambaré el nombre de las columnas en ese sentido \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borro columnas analizadas en el aparte anterior: FECHA_x,AAAA_x,MM_x,DD_x\n",
    "\n",
    "columnas_a_eliminar = ['FECHA_y','AAAA_y', 'MM_y','DD_y', 'ROL', 'LUGAR_DEL_HECHO', 'TIPO_DE_CALLE', 'Altura', 'AAAA_x', 'MM_x','DD_x', 'VICTIMA_y']\n",
    "df_siniestros = df_siniestros.drop(columns=columnas_a_eliminar, axis=1)\n",
    "df_siniestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio el nombre de las columnas posx y pos por LONGITUD y LATITUD, Dado que verifique algunas direcciones normalizadas\n",
    "# y encontré la coincidencia con estas columnas\n",
    "\n",
    "df_siniestros.rename(columns={'pos x'\t: 'LATITUD'}, inplace=True)\n",
    "df_siniestros.rename(columns={'pos y'\t: 'LONGITUD'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombro la columna N_VICTIMAS por No_VICTIMAS\n",
    "\n",
    "df_siniestros.rename(columns={'N_VICTIMAS': 'No_VICTIMAS'}, inplace=True)\n",
    "df_siniestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio el nombre de la columna FECHA_x por FECHA\n",
    "df_siniestros.rename(columns={'FECHA_X': 'FECHA_HECHO'}, inplace=True)\n",
    "df_siniestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio el nombre de la columna FECHA_x por FECHA\n",
    "df_siniestros.rename(columns={'FECHA_X': 'FECHA_HECHO'}, inplace=True)\n",
    "df_siniestros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio el nombre de la columna Calle por CALLE con el fin de estandarizar los títulos\n",
    "df_siniestros.rename(columns={'Calle': 'CALLE'}, inplace=True)\n",
    "\n",
    "# Cambio el nombre de la columna Cruce por CRUCE con el fin de estandarizar los títulos\n",
    "df_siniestros.rename(columns={'Cruce': 'CRUCE'}, inplace=True)\n",
    "\n",
    "# Cambio el nombre de la columna Direcci�n Normalizada por CRUCE con el fin de estandarizar los títulos\n",
    "df_siniestros.rename(columns={'Direcci�n Normalizada': 'DIRECCIÓN'}, inplace=True)\n",
    "\n",
    "# Cambio el nombre de la columna Direcci�n Normalizada por CRUCE con el fin de estandarizar los títulos\n",
    "df_siniestros.rename(columns={'VICTIMA_x': 'VICTIMA'}, inplace=True)\n",
    "\n",
    "df_siniestros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30108 entries, 0 to 30107\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   IDENTIFICADOR        30108 non-null  object \n",
      " 1   ID                   30108 non-null  object \n",
      " 2   No_VICTIMAS          717 non-null    float64\n",
      " 3   FECHA_x              717 non-null    object \n",
      " 4   HORA                 717 non-null    object \n",
      " 5   HH                   717 non-null    object \n",
      " 6   CALLE                716 non-null    object \n",
      " 7   CRUCE                540 non-null    object \n",
      " 8   DIRECCIÓN            708 non-null    object \n",
      " 9   COMUNA               717 non-null    float64\n",
      " 10  XY (CABA)            717 non-null    object \n",
      " 11  LATITUD              717 non-null    object \n",
      " 12  LONGITUD             717 non-null    object \n",
      " 13  PARTICIPANTES        717 non-null    object \n",
      " 14  VICTIMA              717 non-null    object \n",
      " 15  ACUSADO              717 non-null    object \n",
      " 16  SEXO                 717 non-null    object \n",
      " 17  EDAD                 717 non-null    object \n",
      " 18  FECHA_FALLECIMIENTO  717 non-null    object \n",
      "dtypes: float64(2), object(17)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_siniestros.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'columna1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4468\\1201848660.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Para continuar con la visualización correcta ordenaré el data frame por año y luego por identificador\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_siniestros\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_siniestros\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'columna1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'columna2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6923\u001b[0m                 \u001b[1;33mf\"\u001b[0m\u001b[1;33mLength of ascending (\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\"\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6924\u001b[0m                 \u001b[1;33mf\"\u001b[0m\u001b[1;33m != length of by (\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6925\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6926\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6927\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6929\u001b[0m             \u001b[1;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6930\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'columna1'"
     ]
    }
   ],
   "source": [
    "#Para continuar con la visualización correcta ordenaré el data frame por año y luego por identificador\n",
    "\n",
    "df_siniestros = df_siniestros.sort_values(by=['columna1', 'columna2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros duplicados en la columna 'ID':\n",
      "              ID  N_VICTIMAS     FECHA_x  AAAA_x  MM_x  DD_x      HORA   HH  \\\n",
      "30     2016-0041         2.0  29/03/2016  2016.0   3.0  29.0  11:00:00   11   \n",
      "99     2016-0126         2.0  18/09/2016  2016.0   9.0  18.0  22:45:00   22   \n",
      "164    2017-0026         2.0  26/02/2017  2017.0   2.0  26.0   5:15:00    5   \n",
      "174    2017-0035         3.0  23/03/2017  2017.0   3.0  23.0   5:00:00    5   \n",
      "175    2017-0035         3.0  23/03/2017  2017.0   3.0  23.0   5:00:00    5   \n",
      "...          ...         ...         ...     ...   ...   ...       ...  ...   \n",
      "30103        NaN         NaN         NaN     NaN   NaN   NaN       NaN  NaN   \n",
      "30104        NaN         NaN         NaN     NaN   NaN   NaN       NaN  NaN   \n",
      "30105        NaN         NaN         NaN     NaN   NaN   NaN       NaN  NaN   \n",
      "30106        NaN         NaN         NaN     NaN   NaN   NaN       NaN  NaN   \n",
      "30107        NaN         NaN         NaN     NaN   NaN   NaN       NaN  NaN   \n",
      "\n",
      "                                         LUGAR_DEL_HECHO TIPO_DE_CALLE  ...  \\\n",
      "30                        AV DIRECTORIO Y RIVERA INDARTE       AVENIDA  ...   \n",
      "99                                  IRIGOYEN Y TINOGASTA         CALLE  ...   \n",
      "164                         AV. PERITO MORENO Y FOURNIER       AVENIDA  ...   \n",
      "174    AV. DR. TRISTAN ACHAVAL RODRIGUEZ Y BLVD. AZUC...       AVENIDA  ...   \n",
      "175    AV. DR. TRISTAN ACHAVAL RODRIGUEZ Y BLVD. AZUC...       AVENIDA  ...   \n",
      "...                                                  ...           ...  ...   \n",
      "30103                                                NaN           NaN  ...   \n",
      "30104                                                NaN           NaN  ...   \n",
      "30105                                                NaN           NaN  ...   \n",
      "30106                                                NaN           NaN  ...   \n",
      "30107                                                NaN           NaN  ...   \n",
      "\n",
      "           ACUSADO     FECHA_y  AAAA_y MM_y  DD_y                   ROL  \\\n",
      "30          CARGAS  29/03/2016  2016.0  3.0  29.0  PASAJERO_ACOMPA�ANTE   \n",
      "99          CARGAS  18/09/2016  2016.0  9.0  18.0  PASAJERO_ACOMPA�ANTE   \n",
      "164    OBJETO FIJO  26/02/2017  2017.0  2.0  26.0             CONDUCTOR   \n",
      "174    OBJETO FIJO  23/03/2017  2017.0  3.0  23.0  PASAJERO_ACOMPA�ANTE   \n",
      "175    OBJETO FIJO  23/03/2017  2017.0  3.0  23.0  PASAJERO_ACOMPA�ANTE   \n",
      "...            ...         ...     ...  ...   ...                   ...   \n",
      "30103          NaN         NaN     NaN  NaN   NaN                   NaN   \n",
      "30104          NaN         NaN     NaN  NaN   NaN                   NaN   \n",
      "30105          NaN         NaN     NaN  NaN   NaN                   NaN   \n",
      "30106          NaN         NaN     NaN  NaN   NaN                   NaN   \n",
      "30107          NaN         NaN     NaN  NaN   NaN                   NaN   \n",
      "\n",
      "      VICTIMA_y       SEXO EDAD FECHA_FALLECIMIENTO  \n",
      "30         MOTO  MASCULINO   SD          30/03/2016  \n",
      "99         AUTO  MASCULINO   60                  SD  \n",
      "164        AUTO  MASCULINO   19          26/02/2017  \n",
      "174        AUTO  MASCULINO   32          23/03/2017  \n",
      "175        AUTO  MASCULINO   30          23/03/2017  \n",
      "...         ...        ...  ...                 ...  \n",
      "30103       NaN        NaN  NaN                 NaN  \n",
      "30104       NaN        NaN  NaN                 NaN  \n",
      "30105       NaN        NaN  NaN                 NaN  \n",
      "30106       NaN        NaN  NaN                 NaN  \n",
      "30107       NaN        NaN  NaN                 NaN  \n",
      "\n",
      "[29411 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# ID: Identificador contiene año y número, bastaría con el identificador pues hay columna independiente de año, así que primero \n",
    "# verifico si existen registros iguales para poder retirar los cuatro digitos del año y dejer solo el numero identificador \n",
    "# que deja ventajas como organizar facilmente la información\n",
    "\n",
    "# Verificar duplicados en la columna 'Columna'\n",
    "duplicados_df_siniestros = df_siniestros.duplicated(subset='ID')\n",
    "\n",
    "# Imprimir los registros duplicados\n",
    "print(\"Registros duplicados en la columna 'ID':\")\n",
    "print(df_siniestros [duplicados_df_siniestros])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
